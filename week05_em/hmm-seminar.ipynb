{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hidden Markov models for cracking codes**\n",
    "\n",
    "In this exercise you have to make a partially built HMM work and use it to solve some simple substitution ciphers. Plaintext data is provided in 'plaintext' directory. Encrypted data is in 'encrypted'. Some of the texts were originally English some of them were Russian; the sequences are also of different lengths. \n",
    "\n",
    "This homework is worth **15 points** and is due by the next class (**24th Oct.**), please submit the results of the **TASK 5** (a list of files and names of the author/work) to Anytask in the following format: 'filename author' where 'filename' is a file from \"encrypted/\\*_encrypted.txt\" and 'author' is a file from \"plaintext/\\*.txt\" (not including 'english.txt', 'russian.txt' or 'all.txt') which best matches the decrypted text.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilities for loading data from file and converting characters to integers and back.\n",
    "import numpy as np\n",
    "    \n",
    "def get_char_to_int_mapping(path):\n",
    "    # Load data from path and get mapping from characters to integers and back.\n",
    "    characters = set()\n",
    "    for line in open(path):\n",
    "        characters.update(set([c for c in line.strip()]))\n",
    "    char_to_int_mapping = dict([(char, i) for i, char in enumerate(sorted(list(characters)))])\n",
    "    int_to_char_mapping = [char for char, i in char_to_int_mapping.items()]\n",
    "    return char_to_int_mapping, int_to_char_mapping\n",
    "\n",
    "def load_sequences(path, char_to_int_mapping):\n",
    "    # Load data from path and map to integers using mapping.\n",
    "    return [[char_to_int_mapping[c] for c in line.strip()] for line in open(path)]\n",
    "\n",
    "def f(sequences, num_states):\n",
    "    # Estimate a Markov model based on the sequences (integers) provided.\n",
    "\n",
    "    # pi[i] = Pr(s_0 = i)\n",
    "    pi_counts = np.zeros(num_states)\n",
    "\n",
    "    # A[i, j] = Pr(s_t = j | s_{t-1} = i)\n",
    "    A_counts = np.zeros((num_states, num_states))\n",
    "    \n",
    "    for n, sequence in enumerate(sequences):\n",
    "        prev_char = None\n",
    "        for n_char, char in enumerate(sequence):\n",
    "            if n_char == 0:\n",
    "                pi_counts[char] += 1\n",
    "            \n",
    "            if prev_char is not None:\n",
    "                A_counts[prev_char, char] += 1\n",
    "            \n",
    "            prev_char = char\n",
    "#         assert False, \"Collect counts for pi and A and return parameter estimates.\"\n",
    "#     return pi_counts, A_counts\n",
    "    pi = pi_counts / pi_counts.sum()\n",
    "    A = A_counts / A_counts.sum(axis=0)\n",
    "#     assert(np.allclose(A.argmax(axis=0), A_counts.argmax(axis=0)))\n",
    "    \n",
    "    return pi, A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_states = 5\n",
    "# A_counts = np.zeros((num_states, num_states))\n",
    "# sequence = (0,1,1,2,1,3,1,4)\n",
    "# prev_char = None\n",
    "# for n_char, char in enumerate(sequence):\n",
    "#     if prev_char is not None:\n",
    "#         A_counts[prev_char, char] += 1\n",
    "#     prev_char = char\n",
    "    \n",
    "# A_counts.sum(axis=0)\n",
    "# A_counts\n",
    "# A_counts / A_counts.sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK 1**: Make the following block run by completing the method 'estimate_markov_model_from_sequences' above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some data to use.\n",
    "plaintext = 'plaintext/english.txt'\n",
    "# plaintext = 'plaintext/shakespeare.txt'\n",
    "# plaintext = 'plaintext/russian.txt'\n",
    "\n",
    "ciphertext = 'encrypted/1_encrypted.txt' # short sequences in english\n",
    "# ciphertext = 'encrypted/99_encrypted.txt' # longer sequences in russian\n",
    "\n",
    "# load a character to integer mapping and reverse                                                                                                         \n",
    "char_to_int_mapping, int_to_char_mapping = get_char_to_int_mapping(plaintext)\n",
    "\n",
    "# load sequences as ints                                                                                                                                  \n",
    "plaintext_sequences = load_sequences(plaintext, char_to_int_mapping)\n",
    "encrypted_sequences = load_sequences(ciphertext, char_to_int_mapping)\n",
    "\n",
    "# estimate a markov model over characters                                                                                                                 \n",
    "pi, A = estimate_markov_model_from_sequences(plaintext_sequences, len(char_to_int_mapping))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a mostly implemented HMM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning how to multiply stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\alpha_{t+1}(i) = \\sum_{j} \\alpha_{t}(j)A_{j}(i)B_{i}(x_{t+1})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequence = [1, 2, 3, 27]\n",
    "# num_states = 27\n",
    "# num_output_states = 28\n",
    "\n",
    "# alpha = np.random.rand(num_states, len(sequence))\n",
    "# prev_alpha = np.random.rand(num_states, 1)\n",
    "# A = np.random.rand(num_states, num_states)\n",
    "# B = np.random.rand(num_states, num_output_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply_non_numpy_way(alpha, A, B, sequence):\n",
    "    num_states = len(alpha)\n",
    "    \n",
    "    res = np.zeros((num_states, len(sequence)))\n",
    "    for t, xt in enumerate(sequence):\n",
    "        for i in range(num_states):\n",
    "            for j in range(num_states):\n",
    "                res[i, t] += alpha[j, t] * A[i, j] * B[i, xt]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply_numpy_way(alpha, A, B, sequence):\n",
    "    num_states = len(alpha)\n",
    "    \n",
    "    res = np.zeros((num_states, len(sequence)))\n",
    "    for t, xt in enumerate(sequence):\n",
    "        res[:, t] = A.dot(alpha[:, t]) * B[:, xt]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    np.allclose(multiply_numpy_way(alpha, A, B, sequence), multiply_non_numpy_way(alpha, A, B, sequence))\n",
    "except NameError:\n",
    "    print('skip check')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply_non_numpy_way_prev(prev_alpha, A, B, sequence):\n",
    "    num_states = len(prev_alpha)\n",
    "    \n",
    "    res = np.zeros((num_states, len(sequence)))\n",
    "    for t, xt in enumerate(sequence):\n",
    "        for i in range(num_states):\n",
    "            for j in range(num_states):\n",
    "                res[i, t] += prev_alpha[j, 0] * A[i, j] * B[i, xt]\n",
    "        prev_alpha = res[:, t].reshape(-1, 1)\n",
    "        \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply_numpy_way_prev(prev_alpha, A, B, sequence):\n",
    "    num_states = len(alpha)\n",
    "    \n",
    "    res = np.zeros((num_states, len(sequence)))\n",
    "    for t, xt in enumerate(sequence):\n",
    "        res[:, t] = A.dot(prev_alpha).flatten() * B[:, xt]\n",
    "        prev_alpha = res[:, t].copy()\n",
    "        \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    np.allclose(multiply_non_numpy_way_prev(prev_alpha, A, B, sequence), multiply_numpy_way_prev(prev_alpha, A, B, sequence))\n",
    "except NameError:\n",
    "    print('skip check')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\beta_{t}(i) = \\sum_{j}\\beta_{t+1}A_{i}jB_{j}(x_{t+1})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# beta = np.random.rand(num_states, len(sequence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def B_non_numpy_way(beta, A, B, sequence):\n",
    "    num_states = len(beta)\n",
    "    res = np.zeros((num_states, len(sequence)))\n",
    "    \n",
    "    for t, xt in enumerate(sequence):\n",
    "        for i in range(num_states):\n",
    "            for j in range(num_states):\n",
    "                res[i, t] += beta[j, t] * A[j, i] * B[j, xt]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def B_numpy_way(beta, A, B, sequence):\n",
    "    num_states = len(beta)\n",
    "    res = np.zeros((num_states, len(sequence)))\n",
    "    \n",
    "    for t, xt in enumerate(sequence):\n",
    "#         res[i, t] += beta[j,t] * A[j,i] * B[j, xt]\n",
    "        res[:, t] = (beta[:,t] * B[:, xt]).dot(A)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    assert(np.allclose(B_numpy_way(beta, A, B, sequence), B_non_numpy_way(beta, A, B, sequence)))\n",
    "except NameError:\n",
    "    print('skip check')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HMM():\n",
    "\n",
    "    def __init__(self, observations_to_char_mapping={}, states_to_char_mapping={}):\n",
    "        # Determine number of states and observation space. \n",
    "        self.num_states = len(states_to_char_mapping)\n",
    "        self.num_outputs = len(observations_to_char_mapping)\n",
    "        self.states_to_char_mapping = states_to_char_mapping\n",
    "        self.observations_to_char_mapping = observations_to_char_mapping\n",
    "       \n",
    "        # Random initialization\n",
    "        self.pi = np.random.rand(self.num_states)\n",
    "        self.pi /= np.sum(self.pi)\n",
    "        self.A = np.random.rand(self.num_states, self.num_states)\n",
    "        self.A /= np.sum(self.A, 1, keepdims=True)\n",
    "        self.B = np.random.rand(self.num_states, self.num_outputs)\n",
    "        self.B /= np.sum(self.B, 1, keepdims=True) \n",
    "        \n",
    "    def estimate_with_em(self, sequences, parameters={}, epsilon=0.001, max_iters=100):\n",
    "        # Estimates all parameters not provided in 'parameters' based on 'sequences'.\n",
    "        self.fixed_pi = 'pi' in parameters\n",
    "        if self.fixed_pi:\n",
    "            self.pi = parameters['pi']\n",
    "        \n",
    "        self.fixed_A = 'A' in parameters\n",
    "        if self.fixed_A:\n",
    "            self.A = parameters['A']\n",
    "        self.fixed_B = 'B' in parameters\n",
    "        if self.fixed_B:\n",
    "            self.B = parameters['B']\n",
    "    \n",
    "        previous_llh = None\n",
    "        iter = 0\n",
    "        while True and iter < max_iters:\n",
    "            # Infer expected counts.\n",
    "#             try:\n",
    "#                 clear_output()\n",
    "#             except Exception:\n",
    "#                 pass\n",
    "            pi_counts, A_counts, B_counts, log_likelihood = self.e_step(sequences)\n",
    "\n",
    "            # Update parameters based on counts.\n",
    "            self.m_step(pi_counts, A_counts, B_counts)\n",
    "\n",
    "            # Output some sequences for debugging.\n",
    "            self.output(sequences[:10])\n",
    "\n",
    "            # Log likelihood should be increasing\n",
    "            print('iteration %d; log likelihood %.4f' % (iter, log_likelihood))\n",
    "            if previous_llh:\n",
    "                assert log_likelihood >= previous_llh\n",
    "                if log_likelihood - previous_llh < epsilon:\n",
    "                    break\n",
    "            previous_llh = log_likelihood\n",
    "        \n",
    "            iter += 1\n",
    "\n",
    "\n",
    "    def e_step(self, sequences):\n",
    "        # Reset counters of statistics\n",
    "        pi_counts = np.zeros_like(self.pi)\n",
    "        A_counts = np.zeros_like(self.A) \n",
    "        B_counts = np.zeros_like(self.B) \n",
    "        total_log_likelihood = 0.0\n",
    "\n",
    "        for sequence in sequences:\n",
    "            # Run Forward-Backward dynamic program\n",
    "            alpha, beta, gamma, xi, log_likelihood = self.forward_backward(sequence)\n",
    "  \n",
    "            # Accumulate statistics.а с\n",
    "            pi_counts += gamma[:, 0]\n",
    "            A_counts += xi\n",
    "            for t, x in enumerate(sequence):\n",
    "                B_counts[:, x] += gamma[:, t]\n",
    "            \n",
    "            total_log_likelihood += log_likelihood\n",
    "\n",
    "        return pi_counts, A_counts, B_counts, total_log_likelihood\n",
    "\n",
    "    def m_step(self, pi_counts, A_counts, B_counts):\n",
    "        if not self.fixed_pi:\n",
    "            self.pi = pi_counts / np.sum(pi_counts)\n",
    "        if not self.fixed_A:\n",
    "            self.A = A_counts / np.sum(A_counts, 1, keepdims=True)\n",
    "        if not self.fixed_B:\n",
    "            self.B = B_counts / np.sum(B_counts, 1, keepdims=True)\n",
    "        \n",
    "    def max_posterior_decode(self, sequence):\n",
    "        _, _, gamma, _, log_likelihood = self.forward_backward(sequence)\n",
    "        return np.argmax(gamma, 0)\n",
    "        \n",
    "    def forward_backward(self, sequence):\n",
    "        # alpha[i][t] = p(x_1, ..., x_t, z_t = i)\n",
    "        alpha = self.forward(sequence)\n",
    "        \n",
    "        # beta[i][t] = p(x_t+1, ..., x_T|z_t = i)\n",
    "        beta = self.backward(sequence)\n",
    "\n",
    "        # gamma[i][t] = p(z_t = i|x_1, ..., x_T)\n",
    "        gamma = (alpha * beta) / np.sum(alpha * beta, 0)\n",
    "\n",
    "        # xi[i][j] = p(z_t = i, z_{t+1} = j|x_1, ..., x_T)\n",
    "        xi = np.zeros_like(self.A)\n",
    "        for t in range(1, len(sequence)-1):\n",
    "            this_xi = np.zeros_like(self.A)\n",
    "            for i in range(self.num_states):\n",
    "                for j in range(self.num_states):\n",
    "                    this_xi[i, j] += alpha[i, t] * self.A[i, j] * beta[j, t+1] * self.B[j, sequence[t+1]]        \n",
    "            xi += this_xi / np.sum(this_xi)\n",
    "                \n",
    "        return alpha, beta, gamma, xi, np.log(np.sum(alpha[:, len(sequence)-1]))\n",
    "    \n",
    "    def forward(self, sequence):\n",
    "        # alpha[i][t] = p(x_1, ..., x_t, z_t = i)\n",
    "        alpha = np.zeros((len(self.pi), len(sequence)))\n",
    "        correct_alpha_shape = alpha.shape\n",
    "        \n",
    "        for t, xt in enumerate(sequence):\n",
    "            if t == 0:\n",
    "                prev_alpha = self.pi * self.B[:, xt]\n",
    "                alpha_initialized = True\n",
    "            else:\n",
    "                prev_alpha = self.A.dot(prev_alpha).flatten() * self.B[:, xt]\n",
    "                \n",
    "            alpha[:, t] = prev_alpha.copy()\n",
    "        \n",
    "        assert(alpha_initialized)\n",
    "        assert(alpha.shape == correct_alpha_shape)\n",
    "        \n",
    "        return alpha\n",
    "    \n",
    "    def backward(self, sequence):\n",
    "        # beta[i][t] = p(x_t+1, ..., x_T|z_t = i)\n",
    "        num_states = len(self.pi)\n",
    "        beta = np.zeros((num_states, len(sequence)))\n",
    "        \n",
    "    \n",
    "        for ind, xt in enumerate(sequence[::-1]):\n",
    "            t = len(sequence) - ind - 1\n",
    "            if ind == 0:\n",
    "                beta[:, t] = 1.0\n",
    "            else:\n",
    "                for i in range(num_states):\n",
    "                    for j in range(num_states):\n",
    "                        beta[i, t] += beta[j, t+1] * self.A[j, i] * self.B[j, xt_plus1]\n",
    "            xt_plus1 = xt\n",
    "            \n",
    "        return beta\n",
    "\n",
    "    def output(self, sequences):\n",
    "        # Output some decoded states. \n",
    "        for i, sequence in enumerate(sequences):\n",
    "            \n",
    "            observations = [self.observations_to_char_mapping[x] for x in sequence]                \n",
    "            map_states = [self.states_to_char_mapping[x] for x in self.max_posterior_decode(sequence)]\n",
    "            print('(states):       %s\\n(observations): %s' % (''.join(map_states), ''.join(observations)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK 2**: Implement the assertions in 'forward' and 'backward' methods on the HMM class so that the following block passes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since it's a substitution cipher we assume hidden states and observations have same alphabet.\n",
    "state_to_char_mapping = int_to_char_mapping\n",
    "observation_to_char_mapping = int_to_char_mapping\n",
    "\n",
    "# Initialize a HMM with the correct state/output spaces.\n",
    "hmm = HMM(observation_to_char_mapping, state_to_char_mapping)\n",
    "\n",
    "# Estimate the parameters and decode the encrypted sequences.\n",
    "hmm.estimate_with_em(encrypted_sequences[:20],\n",
    "                     parameters={'A' :A,'pi':pi}\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK 3**: Some of the encrypted sequences are quite long. Try decoding some from 'encrypted/99_encrypted.txt' (note these are in Russian)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK 4**: Make your implementation of forward and backward more efficient by removing all but the outermost for-loop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK 5**: Try to classify the author of each text. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
